2025-01-21 17:08:28,728 - INFO - Device: cuda
2025-01-21 17:08:28,729 - INFO - Running with evaluator model normal mode.
2025-01-21 17:08:28,770 - INFO - Succesfully loaded input data.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:36<01:12, 36.30s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:13<00:36, 36.62s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:46<00:00, 35.11s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:46<00:00, 35.48s/it]
2025-01-21 17:10:28,626 - INFO - Using tokenizer.eos_token as the pad token for mistralai/Mistral-7B-Instruct-v0.3.
2025-01-21 17:10:28,627 - INFO - Succesfully loaded evaluator model.
2025-01-21 17:10:28,638 - INFO - Succesfully prepared model inputs.
Processing batches:   0%|          | 0/7 [00:00<?, ?batch/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/leonardo/home/userexternal/sdavenia/ups_gen_dir/ups_gen_env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
Processing batches:  14%|█▍        | 1/7 [00:38<03:52, 38.77s/batch]Processing batches:  29%|██▊       | 2/7 [01:16<03:11, 38.39s/batch]Processing batches:  43%|████▎     | 3/7 [01:53<02:30, 37.59s/batch]Processing batches:  57%|█████▋    | 4/7 [02:29<01:50, 36.99s/batch]Processing batches:  71%|███████▏  | 5/7 [03:05<01:12, 36.48s/batch]Processing batches:  86%|████████▌ | 6/7 [03:48<00:38, 38.76s/batch]Processing batches: 100%|██████████| 7/7 [04:02<00:00, 30.65s/batch]Processing batches: 100%|██████████| 7/7 [04:02<00:00, 34.62s/batch]
2025-01-21 17:14:30,954 - INFO - Succesfully ran the prompts through the model.
2025-01-21 17:14:30,955 - INFO - Failed to decode 1 out of 102 outputs.
2025-01-21 17:14:30,959 - INFO - ../data/generation_processed/Llama-3.1-8B-Instructsmall_complete_run.csv does not exist: creating it...
